{"cells":[{"cell_type":"markdown","metadata":{"id":"in9S_YUyBC-t"},"source":["# Dog Breed Recognition Project"]},{"cell_type":"markdown","metadata":{"id":"4i_hCz4abADf"},"source":["## Project Basics"]},{"cell_type":"markdown","metadata":{"id":"8oZfaZ_xBf0f"},"source":["#### Problem"]},{"cell_type":"markdown","metadata":{"id":"bYcVYrJYCNKn"},"source":["Our goal is to identify dog breed from a photo of the dog.  \n","The project is taken from [Kaggle Dog Breed Identification Competition](https://www.kaggle.com/c/dog-breed-identification/data).  \n","The machine learning problem is **supervised learning > multiclass classification**.  \n","Our task is to build a neural network image classifier using TensorFlow and TensorFlow Hub."]},{"cell_type":"markdown","metadata":{"id":"fzDR79sXBi51"},"source":["#### Evaluation"]},{"cell_type":"markdown","metadata":{"id":"fDhitkMhGtRO"},"source":["The evaluation metric set for the competition is Multiclass Log Loss.  \n","Our target matrix contains N Dogs x M Breeds, true breed = 1, rest = 0.  \n","Our model predicts a probability matrix with the same dimensions.  \n","Multiclass Log Loss measures the error of model predictions (the lower the better).  \n","Muticlass Log Loss is applied in image classification, natural language processing, and recommendation systems."]},{"cell_type":"markdown","metadata":{"id":"5jAW9IvXBrec"},"source":["#### Data Source"]},{"cell_type":"markdown","metadata":{"id":"pxafFCqUDZg2"},"source":["Data is acquired from [Kaggle Dog Breed Identification Competition](https://www.kaggle.com/c/dog-breed-identification/data)."]},{"cell_type":"markdown","metadata":{"id":"3p5Qyin9BuSG"},"source":["#### Features / Data Dictionary"]},{"cell_type":"markdown","metadata":{"id":"DnGXzu-CKCie"},"source":["Our model analyzes image files (unstructured data) > deep learning / transfer learning.  \n","There are 120 unique dog breeds in the training set > multiclass classification with 120 classes.  \n","There are 10 222 images in the training set.  \n","There are 10 357 images in the test set."]},{"cell_type":"markdown","metadata":{"id":"1-7sc5BnNrJe"},"source":["## Importing Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F8J6sQlQNuiw"},"outputs":[],"source":["### importing tensorflow\n","import tensorflow as tflow\n","print(tflow.__version__)\n","from tensorflow.python.framework.ops import EagerTensor\n","import keras\n","\n","### checking gpu availability\n","print(tflow.config.list_physical_devices())\n","\n","### importing tensorflow hub\n","import tensorflow_hub as thub\n","print(thub.__version__)\n","\n","### python libraries\n","from pathlib import Path\n","from datetime import datetime\n","\n","### external libraries\n","import numpy\n","from pandas import read_csv, DataFrame, concat\n","from matplotlib import pyplot\n","from IPython.display import Image"]},{"cell_type":"markdown","metadata":{"id":"i0xxhYPvd8K6"},"source":["## Importing Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u48Ajtis9-YI"},"outputs":[],"source":["### importing labels\n","labels_df = read_csv(filepath_or_buffer=\"data-files-labels.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RmkelXF9Yz9i"},"outputs":[],"source":["### exploring labels: head\n","labels_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iJqTWZ9p4chr"},"outputs":[],"source":["### exploring labels: info\n","labels_df.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5tKl0ZEPZSkD"},"outputs":[],"source":["### exploring labels: unique breeds\n","unique_breeds = labels_df[\"breed\"].to_numpy()\n","unique_breeds = numpy.unique(ar=unique_breeds)\n","len(unique_breeds)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_BJk_mIw8R5v"},"outputs":[],"source":["### exploring labels: mean of images/breed\n","round(number=labels_df[\"breed\"].value_counts().mean(), ndigits=3)"]},{"cell_type":"markdown","metadata":{"id":"oXyJNET9-Ojj"},"source":["Google recommends at least 10 images per class.  \n","We have adequate data with ~85 images per class on average."]},{"cell_type":"markdown","metadata":{"id":"pCXN_n-xNbh3"},"source":["## Preparing Data"]},{"cell_type":"markdown","metadata":{"id":"oqVWPEF_2eyt"},"source":["#### Creating Image Filepaths"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OmFT6NELYLyq"},"outputs":[],"source":["### counting number of images in train folder\n","image_list = [image for image in Path(\"D:/WorkDev_GitHub/projectData/dataDogRecognition/train\").iterdir()]\n","len(image_list)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ObAn-Q-vUNNO"},"outputs":[],"source":["### creating image filepaths from image ids\n","labels_df[\"imagepath\"] = \"D:/WorkDev_GitHub/projectData/dataDogRecognition/train/\" + labels_df[\"id\"] + \".jpg\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1G_5ZkpGbbsy"},"outputs":[],"source":["### exploring imagepaths: head\n","labels_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dEQZQ0lartA1"},"outputs":[],"source":["### exploring imagepaths: info\n","labels_df.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oNwXN8AaSd1K"},"outputs":[],"source":["### exploring imagepaths: checking validity of random imagepath\n","print(labels_df.loc[9000, \"breed\"])\n","print()\n","print(labels_df.loc[9000, \"imagepath\"])\n","print()\n","Image(filename=labels_df.loc[9000, \"imagepath\"])"]},{"cell_type":"markdown","metadata":{"id":"Yiwac2F6pSZY"},"source":["#### Reducing and Splitting"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CFvyl-ZfPc3C"},"outputs":[],"source":["### dataframe inits\n","fTrain_df = DataFrame()\n","fValid_df = DataFrame()\n","tTrain_df = DataFrame()\n","tValid_df = DataFrame()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SbEuS-H5rjFA"},"outputs":[],"source":["### creating train and valid dataframes\n","for breed in unique_breeds:\n","  work_df: DataFrame = DataFrame()\n","  work_df = labels_df.loc[labels_df[\"breed\"] == breed]\n","  work_df = work_df.sample(n=work_df.index.size, random_state=42)\n","  train_num = int(0.8 * work_df.index.size)\n","  valid_num = work_df.index.size - train_num\n","  fTrain_df = concat(objs=[fTrain_df, work_df.iloc[:train_num]])\n","  fValid_df = concat(objs=[fValid_df, work_df.iloc[train_num:]])\n","  work_df = work_df.sample(n=12, random_state=42)\n","  tTrain_df = concat(objs=[tTrain_df, work_df.iloc[:10]])\n","  tValid_df = concat(objs=[tValid_df, work_df.iloc[10:]])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r1A871GaO-Rr"},"outputs":[],"source":["### shuffling train dataframes\n","fTrain_df = fTrain_df.sample(n=fTrain_df.index.size, random_state=42)\n","tTrain_df = tTrain_df.sample(n=tTrain_df.index.size, random_state=42)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"89mvfHSw5TD4"},"outputs":[],"source":["### verifying dimensions of train and valid dataframes\n","fTrain_df.shape, fValid_df.shape, tTrain_df.shape, tValid_df.shape"]},{"cell_type":"markdown","metadata":{"id":"wLoH-H1_nekD"},"source":["#### Creating Tensors"]},{"cell_type":"markdown","metadata":{"id":"oXbLq4rs2kLa"},"source":["All machine learning algorithms require data in numerical format.  \n","So the first task is to turn images and labels into tensors.  \n","A tensor is a numerical matrix with n-dimensions, like a numpy ndarray."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"076CXYAb4Cvp"},"outputs":[],"source":["### function creating image tensor array\n","def imageTensor(aInput_df=DataFrame(), aImage_size=224):\n","  \"\"\"\n","  Converts image files into constant image tensors.\\n\n","  Combines individual image tensors into a tensor array.\n","  \"\"\"\n","  counter = 0\n","  tensor_array = numpy.empty(shape=(0,224,224,3), dtype=numpy.float32)\n","  for _,row in aInput_df.iterrows():\n","    print(counter)\n","    image_tensor = tflow.io.read_file(filename=row[\"imagepath\"])\n","    image_tensor = tflow.image.decode_jpeg(contents=image_tensor, channels=3)\n","    image_tensor = tflow.image.convert_image_dtype(image=image_tensor, dtype=tflow.float32)\n","    image_tensor = tflow.image.resize(images=image_tensor, size=[aImage_size, aImage_size])\n","    tensor_array = numpy.append(arr=tensor_array, values=numpy.array([image_tensor]), axis=0)\n","    counter += 1\n","  return tflow.constant(value=tensor_array)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uSFFEb0KrF0i"},"outputs":[],"source":["### creating and saving trial train images tensor array\n","tTrain_images = imageTensor(aInput_df=tTrain_df, aImage_size=224)\n","numpy.save(arr=tTrain_images, file=\"tTrain-images.npy\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["### creating and saving trial valid images tensor array\n","tValid_images = imageTensor(aInput_df=tValid_df, aImage_size=224)\n","numpy.save(arr=tValid_images.numpy(), file=\"tValid-images.npy\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kxQQM9B_n93F"},"outputs":[],"source":["### function creating labels tensor\n","def labelTensor(pInput_df=DataFrame()):\n","  \"\"\"\n","  Creates a label tensor from breed names.\n","  \"\"\"\n","  tensor_list = list()\n","  for index,row in pInput_df.iterrows():\n","    print(index)\n","    label_array = numpy.zeros(shape=120, dtype=\"int8\")\n","    label_array[numpy.where(unique_breeds == row[\"breed\"])] = 1\n","    tensor_list.append(tflow.constant(value=label_array))\n","  return tflow.stack(values=tensor_list, axis=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"55BjpDknNNwK"},"outputs":[],"source":["### creating and saving train labels tensor\n","train_labels = labelTensor(pInput_df=train_df)\n","numpy.save(arr=train_labels.numpy(), file=\"drive/MyDrive/ColabData/DogRecognition/tensors/train-labels.npy\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-NDMShCkvLI8"},"outputs":[],"source":["### creating and saving valid labels tensor\n","valid_labels = labelTensor(pInput_df=valid_df)\n","numpy.save(arr=valid_labels.numpy(), file=\"drive/MyDrive/ColabData/DogRecognition/tensors/valid-labels.npy\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SeClHn0wSxTN"},"outputs":[],"source":["### reloading image and label tensors\n","train_images = tflow.constant(value=numpy.load(file=\"drive/MyDrive/ColabData/DogRecognition/tensors/train-images.npy\"))\n","valid_images = tflow.constant(value=numpy.load(file=\"drive/MyDrive/ColabData/DogRecognition/tensors/valid-images.npy\"))\n","train_labels = tflow.constant(value=numpy.load(file=\"drive/MyDrive/ColabData/DogRecognition/tensors/train-labels.npy\"))\n","valid_labels = tflow.constant(value=numpy.load(file=\"drive/MyDrive/ColabData/DogRecognition/tensors/valid-labels.npy\"))\n","train_images.shape, valid_images.shape, train_labels.shape, valid_labels.shape"]},{"cell_type":"markdown","metadata":{"id":"Zbg__wK5ucV0"},"source":["#### Data Batches"]},{"cell_type":"markdown","metadata":{"id":"VXC0FXyJuuVs"},"source":["GPUs have limited amount of memory.  \n","The entire training dataset may not fit into GPU memory.  \n","To resolve this, we split our datasets into batches of ~32 tensors.  \n","The neural network sees only one batch at a time."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cPvLDLC4efLI"},"outputs":[],"source":["### function creating data batches\n","def dataBatches(pInput_tensors=tuple(), pBatch_size=32):\n","  \"\"\"\n","  Creates data batches from input tensors.\n","  \"\"\"\n","  ### creating dataset\n","  data_set = tflow.data.Dataset.from_tensor_slices(tensors=pInput_tensors)\n","  ### creating and returning data batches\n","  return data_set.batch(batch_size=pBatch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iCUH7R1bRY21"},"outputs":[],"source":["### creating train data batches\n","train_batches = dataBatches(pInput_tensors=(train_images,train_labels), pBatch_size=32)\n","train_batches.element_spec"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wtUJtnERDVDZ"},"outputs":[],"source":["### creating valid data batches\n","valid_batches = dataBatches(pInput_tensors=(valid_images,valid_labels), pBatch_size=32)\n","valid_batches.element_spec"]},{"cell_type":"markdown","metadata":{"id":"oHEv7LC_Uv7n"},"source":["#### Visualizing Datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WAW3kh5jVI2f"},"outputs":[],"source":["### function visualizing a data batch\n","def visualizeBatch(pImages=numpy.array([]), pLabels=numpy.array([])):\n","  \"\"\"\n","  Displays images and labels from a data batch.\n","  \"\"\"\n","  pyplot.figure(figsize=(8,12))\n","  for index,image,label in zip(range(1, 33), pImages, pLabels):\n","    axis = pyplot.subplot(8, 4, index)\n","    pyplot.imshow(X=image)\n","    pyplot.title(label=unique_breeds[label.argmax()], fontsize=8)\n","    pyplot.axis(\"off\")\n","  return"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uxyhy8LcVtYf"},"outputs":[],"source":["### visualizing first batch of train bathes\n","images,labels = next(train_batches.as_numpy_iterator())\n","visualizeBatch(pImages=images, pLabels=labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b3M3Q2xxZN_x"},"outputs":[],"source":["### visualizing first batch of valid bathes\n","images,labels = next(valid_batches.as_numpy_iterator())\n","visualizeBatch(pImages=images, pLabels=labels)"]},{"cell_type":"markdown","metadata":{"id":"lcOLS9ljfgUd"},"source":["## Building and Training a Model"]},{"cell_type":"markdown","metadata":{"id":"c9pfIHr1wCJm"},"source":["#### Defining the Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sOnyYIosftAv"},"outputs":[],"source":["### setting base model features\n","INPUT_SHAPE = [None, 224, 224, 3] # batch, height, width, colorchannel\n","MODEL_URL = \"https://www.kaggle.com/models/google/mobilenet-v2/TensorFlow2/130-224-classification/2\"\n","OUTPUT_SHAPE = len(unique_breeds) # number of classes (breeds)\n","NUM_EPOCHS = 100"]},{"cell_type":"markdown","metadata":{"id":"BRMG1TCokIKe"},"source":["**Optimal model parameters:**\n","- for binary classification: sigmoid (activation), binary crossentropy (loss)  \n","- for multiclass classification: softmax (activation), categorical crossentropy (loss)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fbAEyeGGVWsj"},"outputs":[],"source":["### function defining the model\n","def defineModel(pInput_shape=list(), pModel_url=str(), pOutput_shape=int()):\n","  \"\"\"\n","  Defines a deep learning neural network model.\n","  \"\"\"\n","  ### setting model layers\n","  cnn_model = tflow.keras.Sequential([\n","      tfhub.KerasLayer(handle=pModel_url), # input layer\n","      tflow.keras.layers.Dense(units=pOutput_shape, activation=\"softmax\")]) # output layer\n","  ### compiling model (training characteristics)\n","  cnn_model.compile(\n","      loss=tflow.keras.losses.CategoricalCrossentropy(), # basically an error function\n","      optimizer=tflow.keras.optimizers.Adam(), # optimizer algorithm\n","      metrics=[\"accuracy\"])\n","  ### building model (providing input shape)\n","  cnn_model.build(pInput_shape) # shape of input dataset\n","  return cnn_model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2RGeNI2Nb28N"},"outputs":[],"source":["### defining and exploring the model\n","vision_model = defineModel(pInput_shape=INPUT_SHAPE, pModel_url=MODEL_URL, pOutput_shape=OUTPUT_SHAPE)\n","print(type(vision_model))\n","vision_model.summary()"]},{"cell_type":"markdown","metadata":{"id":"NUXNWXmZxi9O"},"source":["#### Creating Callbacks"]},{"cell_type":"markdown","metadata":{"id":"O6twb53lxnD3"},"source":["**Callbacks are event handler functions that are called at certain model training events.**"]},{"cell_type":"markdown","metadata":{"id":"4QL9ozxH7Qg7"},"source":["The TensorBoard() callback saves a training log that helps in monitoring the training process."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dj89dRsL1TNk"},"outputs":[],"source":["### loading tensorboard notebook extension\n","%load_ext tensorboard"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4pizT23D191Q"},"outputs":[],"source":["### creating tensorboard callback\n","def callbackTensorboard():\n","  log_root = Path(\"drive/MyDrive/ColabData/DogRecognition/training_logs\")\n","  log_folder = log_root.joinpath(datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n","  return tflow.keras.callbacks.TensorBoard(log_dir=log_folder)"]},{"cell_type":"markdown","metadata":{"id":"X7ASHBES7fBr"},"source":["The EarlyStopping() callback halts training when a chosen metric stops improving.  \n","It is one of the ways of preventing overfitting."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t8zNAKSw8Gqo"},"outputs":[],"source":["### creating early stopping callback\n","early_stopping = tflow.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=8)"]},{"cell_type":"markdown","metadata":{"id":"UUJcuUE-8Lyk"},"source":["#### Training the Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ifMZVjz18SHw"},"outputs":[],"source":["### function creating trained model\n","def trainModel():\n","  \"\"\"\n","  Defines and trains the deep learning neural network.\n","  \"\"\"\n","  ### defining model\n","  cnn_model = defineModel(pInput_shape=INPUT_SHAPE, pModel_url=MODEL_URL, pOutput_shape=OUTPUT_SHAPE)\n","  ### tensorboard session init\n","  tensor_board = callbackTensorboard()\n","  ### training model\n","  cnn_model.fit(\n","      x=train_batches,\n","      epochs=NUM_EPOCHS,\n","      validation_data=valid_batches,\n","      validation_freq=1,\n","      callbacks=[tensor_board,early_stopping])\n","  return cnn_model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GoP1RI19-Ypy"},"outputs":[],"source":["### training model\n","trained_model = trainModel()"]},{"cell_type":"markdown","metadata":{"id":"DPwFDWHSDyXD"},"source":["#### Model Evaluation with TensorBoard"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z80RltbTD4YJ"},"outputs":[],"source":["### loading tensorboard\n","%tensorboard --logdir drive/MyDrive/ColabData/DogRecognition/training_logs"]},{"cell_type":"markdown","metadata":{"id":"T9Q38yKAmkB5"},"source":["## Visualizing Predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A-bfp_3ErU2i"},"outputs":[],"source":["### making predictions\n","valid_preds = trained_model.predict(x=valid_batches, verbose=True)\n","valid_preds.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XSjpPZho_m13"},"outputs":[],"source":["### function plotting image, true label, and top predictions\n","def plotPreds(aImages=numpy.ndarray([]), aLabels=numpy.ndarray([]), aPreds=numpy.ndarray([]), aIndex=int()):\n","  \"\"\"\n","  Plots an image of a dog, its true breed, and the top predicted breeds for sample aIndex.\n","  \"\"\"\n","  ### figure init\n","  if aIndex < 0: aIndex = 0\n","  if len(aPreds) <= aIndex: aIndex = len(aPreds) - 1\n","  pyplot.figure(figsize=(7,4.5))\n","  ### plotting image and true label\n","  image_plot = pyplot.subplot(1, 2, 1)\n","  image_plot.imshow(X=aImages[aIndex])\n","  image_plot.set_title(label=unique_breeds[numpy.argmax(a=aLabels[aIndex])], fontsize=10)\n","  image_plot.set_yticks(ticks=[])\n","  image_plot.set_xticks(ticks=[])\n","  ### plotting top 5 predictions\n","  top_indexes = numpy.argsort(a=aPreds[aIndex])[-5:][::-1]\n","  pred_plot = pyplot.subplot(1, 2, 2)\n","  pred_plot.bar(height=aPreds[aIndex][top_indexes], x=range(5))\n","  pred_plot.set_title(label=\"Top Five Predictions\", fontsize=10)\n","  pred_plot.set_ylabel(ylabel=\"Confidence Levels\", fontsize=10)\n","  pred_plot.set_xticks(ticks=range(5), labels=unique_breeds[top_indexes], rotation=\"vertical\")\n","  ### layout and returning\n","  pyplot.tight_layout(h_pad=0.1)\n","  return"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5n-wROTTJdQL"},"outputs":[],"source":["plotPreds(aImages=valid_images, aLabels=valid_labels, aPreds=valid_preds, aIndex=44)"]},{"cell_type":"markdown","metadata":{"id":"EYh_3fcIoEx6"},"source":["Challenge: Create a confusion matrix of true labels versus predictions."]},{"cell_type":"markdown","metadata":{"id":"P3paPAYI1g8_"},"source":["## Saving and Loading Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1Dl1rr7D1m2F"},"outputs":[],"source":["### function saving trained model\n","def saveModel(aModel=keras.src.engine.sequential.Sequential(), aFile_name=str()):\n","  \"\"\"\n","  DocString\n","  \"\"\"\n","  models_root = Path(\"drive/MyDrive/ColabData/DogRecognition/models\")\n","  model_dir = models_root.joinpath(datetime.now().strftime(\"%Y%M%D-%H%M%S\"))\n","  model_path = model_dir.joinpath(f\"{aFile_name}.h5\")\n","  print(f\"Saving model: {model_path.resolve()}\")\n","  return"]},{"cell_type":"markdown","metadata":{"id":"hlGcPdCnKeol"},"source":["#### Reducing Data: Working Subset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LwpycO0VKrAI"},"outputs":[],"source":["### splitting data working / rest\n","PERCENT_IMAGES = 0.1 #@param {type:\"slider\", min:0.1, max:1.0, step:0.1}\n","rest_features, work_features, rest_targets, work_targets = train_test_split(\n","    features_series,\n","    targets_df,\n","    test_size=PERCENT_IMAGES,\n","    random_state=42)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPTgQQN0TBCA4ihfBJyMXrt","gpuType":"T4","mount_file_id":"1JM4XGtvqAm8PHoWANtGNGeeXWwJ8O4hI","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":0}
