{"cells":[{"cell_type":"markdown","metadata":{"id":"in9S_YUyBC-t"},"source":["# Dog Breed Recognition Project"]},{"cell_type":"markdown","metadata":{"id":"4i_hCz4abADf"},"source":["## Project Basics"]},{"cell_type":"markdown","metadata":{"id":"8oZfaZ_xBf0f"},"source":["#### Problem"]},{"cell_type":"markdown","metadata":{"id":"bYcVYrJYCNKn"},"source":["Our goal is to identify dog breed from a photo of the dog.  \n","The project is taken from [Kaggle Dog Breed Identification Competition](https://www.kaggle.com/c/dog-breed-identification/data).  \n","The machine learning problem is **supervised learning > multiclass classification**.  \n","Our task is to build a neural network image classifier using TensorFlow and TensorFlow Hub."]},{"cell_type":"markdown","metadata":{"id":"fzDR79sXBi51"},"source":["#### Evaluation"]},{"cell_type":"markdown","metadata":{"id":"fDhitkMhGtRO"},"source":["The evaluation metric set for the competition is Multiclass Log Loss.  \n","Our target matrix contains N Dogs x M Breeds, true breed = 1, rest = 0.  \n","Our model predicts a probability matrix with the same dimensions.  \n","Multiclass Log Loss measures the error of model predictions (the lower the better).  \n","Muticlass Log Loss is applied in image classification, natural language processing, and recommendation systems."]},{"cell_type":"markdown","metadata":{"id":"5jAW9IvXBrec"},"source":["#### Data Source"]},{"cell_type":"markdown","metadata":{"id":"pxafFCqUDZg2"},"source":["Data is acquired from [Kaggle Dog Breed Identification Competition](https://www.kaggle.com/c/dog-breed-identification/data)."]},{"cell_type":"markdown","metadata":{"id":"3p5Qyin9BuSG"},"source":["#### Features / Data Dictionary"]},{"cell_type":"markdown","metadata":{"id":"DnGXzu-CKCie"},"source":["Our model analyzes image files (unstructured data) > deep learning / transfer learning.  \n","There are 120 unique dog breeds in the training set > multiclass classification with 120 classes.  \n","There are 10 222 images in the training set.  \n","There are 10 357 images in the test set."]},{"cell_type":"markdown","metadata":{"id":"1-7sc5BnNrJe"},"source":["## Importing Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F8J6sQlQNuiw"},"outputs":[],"source":["### importing tensorflow\n","import tensorflow as tflow\n","print(tflow.__version__)\n","print(tflow.config.list_physical_devices())\n","\n","### importing tensorflow hub\n","import tensorflow_hub as thub\n","print(thub.__version__)\n","\n","### python libraries\n","from pathlib import Path\n","from math import ceil\n","from datetime import datetime\n","\n","### external libraries\n","import numpy\n","from pandas import read_csv, DataFrame, concat\n","from matplotlib import pyplot\n","from IPython.display import Image"]},{"cell_type":"markdown","metadata":{"id":"i0xxhYPvd8K6"},"source":["## Importing Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u48Ajtis9-YI"},"outputs":[],"source":["### importing labels\n","labels_df = read_csv(filepath_or_buffer=\"data-files-labels.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RmkelXF9Yz9i"},"outputs":[],"source":["### exploring labels: head\n","labels_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iJqTWZ9p4chr"},"outputs":[],"source":["### exploring labels: info\n","labels_df.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5tKl0ZEPZSkD"},"outputs":[],"source":["### exploring labels: unique breeds\n","unique_breeds = labels_df[\"breed\"].to_numpy()\n","unique_breeds = numpy.unique(ar=unique_breeds)\n","len(unique_breeds)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_BJk_mIw8R5v"},"outputs":[],"source":["### exploring labels: mean of images/breed\n","round(number=labels_df[\"breed\"].value_counts().mean(), ndigits=3)"]},{"cell_type":"markdown","metadata":{"id":"oXyJNET9-Ojj"},"source":["Google recommends at least 10 images per class.  \n","We have adequate data with ~85 images per class on average."]},{"cell_type":"markdown","metadata":{"id":"pCXN_n-xNbh3"},"source":["## Preparing Data"]},{"cell_type":"markdown","metadata":{"id":"oqVWPEF_2eyt"},"source":["#### Creating Image Filepaths"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OmFT6NELYLyq"},"outputs":[],"source":["### counting number of images in train folder\n","image_list = [image for image in Path(\"D:/WorkDev_GitHub/projectData/dataDogRecognition/train\").iterdir()]\n","len(image_list)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ObAn-Q-vUNNO"},"outputs":[],"source":["### creating image filepaths from image ids\n","labels_df[\"imagepath\"] = \"D:/WorkDev_GitHub/projectData/dataDogRecognition/train/\" + labels_df[\"id\"] + \".jpg\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1G_5ZkpGbbsy"},"outputs":[],"source":["### exploring imagepaths: head\n","labels_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dEQZQ0lartA1"},"outputs":[],"source":["### exploring imagepaths: info\n","labels_df.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oNwXN8AaSd1K"},"outputs":[],"source":["### exploring imagepaths: checking validity of random imagepath\n","print(labels_df.loc[9000, \"breed\"])\n","print()\n","print(labels_df.loc[9000, \"imagepath\"])\n","print()\n","Image(filename=labels_df.loc[9000, \"imagepath\"])"]},{"cell_type":"markdown","metadata":{"id":"Yiwac2F6pSZY"},"source":["#### Reducing and Splitting"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CFvyl-ZfPc3C"},"outputs":[],"source":["### dataframe inits\n","fTrain_df = DataFrame()\n","fValid_df = DataFrame()\n","rTrain_df = DataFrame()\n","rValid_df = DataFrame()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SbEuS-H5rjFA"},"outputs":[],"source":["### creating train and valid dataframes\n","for breed in unique_breeds:\n","    work_df: DataFrame = DataFrame()\n","    work_df = labels_df.loc[labels_df[\"breed\"] == breed]\n","    work_df = work_df.sample(n=work_df.index.size, random_state=42)\n","    train_num = int(0.9 * work_df.index.size)\n","    valid_num = work_df.index.size - train_num\n","    fTrain_df = concat(objs=[fTrain_df, work_df.iloc[:train_num]])\n","    fValid_df = concat(objs=[fValid_df, work_df.iloc[train_num:]])\n","    work_df = work_df.sample(n=12, random_state=42)\n","    rTrain_df = concat(objs=[rTrain_df, work_df.iloc[:10]])\n","    rValid_df = concat(objs=[rValid_df, work_df.iloc[10:]])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r1A871GaO-Rr"},"outputs":[],"source":["### shuffling train dataframes\n","fTrain_df = fTrain_df.sample(n=fTrain_df.index.size, random_state=42)\n","rTrain_df = rTrain_df.sample(n=rTrain_df.index.size, random_state=42)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"89mvfHSw5TD4"},"outputs":[],"source":["### verifying dimensions of train and valid dataframes\n","fTrain_df.shape, fValid_df.shape, rTrain_df.shape, rValid_df.shape"]},{"cell_type":"markdown","metadata":{"id":"wLoH-H1_nekD"},"source":["#### Creating Datasets"]},{"cell_type":"markdown","metadata":{"id":"oXbLq4rs2kLa"},"source":["All machine learning algorithms require data in numerical format.  \n","So the first task is to turn images and labels into tensors.  \n","A tensor is a numerical matrix with n-dimensions, like a numpy ndarray."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"076CXYAb4Cvp"},"outputs":[],"source":["### function creating image tensors\n","def imageTensor(aInput_df=DataFrame(), aImage_size=224):\n","    \"\"\"\n","    Converts image files into constant image tensors.\\n\n","    Combines individual image tensors into a tensor array.\n","    \"\"\"\n","    tensor_array = numpy.empty(shape=(0,224,224,3), dtype=numpy.float32)\n","    for _,row in aInput_df.iterrows():\n","        image_tensor = tflow.io.read_file(filename=row[\"imagepath\"])\n","        image_tensor = tflow.image.decode_jpeg(contents=image_tensor, channels=3)\n","        image_tensor = tflow.image.convert_image_dtype(image=image_tensor, dtype=tflow.float32)\n","        image_tensor = tflow.image.resize(images=image_tensor, size=[aImage_size,aImage_size])\n","        tensor_array = numpy.append(arr=tensor_array, values=numpy.array([image_tensor]), axis=0)\n","    return tflow.constant(value=tensor_array)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["### function creating label tensors\n","def labelTensor(aInput_df=DataFrame()):\n","    \"\"\"\n","    Encodes true dog breeds into constant label tensors.\\n\n","    Combines individual label tensors into a tensor array.\n","    \"\"\"\n","    tensor_array = numpy.empty(shape=(0,120), dtype=numpy.int8)\n","    for _,row in aInput_df.iterrows():\n","        label_tensor = numpy.zeros(shape=120, dtype=numpy.int8)\n","        label_tensor[numpy.where(unique_breeds == row[\"breed\"])] = 1\n","        tensor_array = numpy.append(arr=tensor_array, values=numpy.array([label_tensor]), axis=0)\n","    return tflow.constant(value=tensor_array)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["### function creating dataset\n","def createDataset(tInput_df=DataFrame()):\n","    \"\"\"\n","    Creates image and label tensors.\\\n","    Combines tensors into a keras dataset.\n","    \"\"\"\n","    counter = 1\n","    num_shards = ceil(tInput_df.index.size / 256)\n","    for index in range(0, tInput_df.index.size, 256):\n","        print(f\"Batch {counter} / {num_shards}\\r\", end=\"\")\n","        image_tensors = imageTensor(aInput_df=tInput_df.iloc[index:index+256], aImage_size=224)\n","        label_tensors = labelTensor(aInput_df=tInput_df.iloc[index:index+256])\n","        if index == 0:\n","            full_dataset = tflow.data.Dataset.from_tensor_slices(tensors=(image_tensors,label_tensors))\n","        else:\n","            shard_dataset = tflow.data.Dataset.from_tensor_slices(tensors=(image_tensors,label_tensors))\n","            full_dataset = full_dataset.concatenate(dataset=shard_dataset)\n","        counter += 1  \n","    return full_dataset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["### creating full train dataset\n","fTrain_dataset = createDataset(tInput_df=fTrain_df)\n","fTrain_dataset.element_spec"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["### creating full valid dataset\n","fValid_dataset = createDataset(tInput_df=fValid_df)\n","fValid_dataset.element_spec"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["### creating reduced train dataset\n","rTrain_dataset = createDataset(tInput_df=rTrain_df)\n","rTrain_dataset.element_spec"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["### creating reduced valid dataset\n","rValid_dataset = createDataset(tInput_df=rValid_df)\n","rValid_dataset.element_spec"]},{"cell_type":"markdown","metadata":{"id":"oHEv7LC_Uv7n"},"source":["#### Visualizing Datasets"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["### function extracting first 32 image/label tensors from dataset\n","def extractTensors(aDataset=tflow.data.Dataset.from_tensor_slices([])):\n","    images = numpy.empty(shape=(0,224,224,3), dtype=numpy.float32)\n","    labels = numpy.empty(shape=(0,120), dtype=numpy.int8)\n","    for image,label in aDataset.as_numpy_iterator():\n","        images = numpy.append(arr=images, values=[image], axis=0)\n","        labels = numpy.append(arr=labels, values=[label], axis=0)\n","        if len(images) == 32: break\n","    return images, labels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WAW3kh5jVI2f"},"outputs":[],"source":["### function visualizing 32 image/label tensors\n","def visualizeTensors(aImages=numpy.array([]), aLabels=numpy.array([])):\n","    \"\"\"\n","    Displays 32 image/label tensor pairs from a tensorflow dataset.\n","    \"\"\"\n","    pyplot.figure(figsize=(8,12))\n","    for index,image,label in zip(range(1, 33), aImages, aLabels):\n","        label: numpy.ndarray\n","        pyplot.subplot(8, 4, index)\n","        pyplot.imshow(X=image)\n","        pyplot.title(label=unique_breeds[label.argmax()], fontsize=8)\n","        pyplot.axis(\"off\")\n","    return"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["### visualizing full train dataset\n","images,labels = extractTensors(aDataset=fTrain_dataset)\n","visualizeTensors(aImages=images, aLabels=labels)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["### visualizing full valid dataset\n","images,labels = extractTensors(aDataset=fValid_dataset)\n","visualizeTensors(aImages=images, aLabels=labels)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["### visualizing reduced train dataset\n","images,labels = extractTensors(aDataset=rTrain_dataset)\n","visualizeTensors(aImages=images, aLabels=labels)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["### visualizing valid dataset\n","images,labels = extractTensors(aDataset=rValid_dataset)\n","visualizeTensors(aImages=images, aLabels=labels)"]},{"cell_type":"markdown","metadata":{"id":"lcOLS9ljfgUd"},"source":["## Preparing Neural Network"]},{"cell_type":"markdown","metadata":{"id":"c9pfIHr1wCJm"},"source":["#### Creating Neural Network"]},{"cell_type":"markdown","metadata":{},"source":["**Optimal network parameters:**  \n","for binary classification: sigmoid (activation), binary crossentropy (loss)  \n","for multiclass classification: softmax (activation), categorical crossentropy (loss)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sOnyYIosftAv"},"outputs":[],"source":["### setting base network features\n","INPUT_SHAPE = [None, 224, 224, 3] # batch, height, width, colorchannel\n","MODEL_URL = \"https://www.kaggle.com/models/google/mobilenet-v2/TensorFlow2/130-224-classification/2\"\n","OUTPUT_SHAPE = len(unique_breeds) # number of classes (breeds)\n","NUM_EPOCHS = 100"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fbAEyeGGVWsj"},"outputs":[],"source":["### function creating neural network\n","def createNetwork(aInput_shape=list(), aModel_url=str(), aOutput_shape=int()):\n","    \"\"\"\n","    Creates a deep learning neural network.\n","    \"\"\"\n","    ### defining network architecture\n","    neural_net = tflow.keras.Sequential([\n","        thub.KerasLayer(handle=aModel_url), # input layer\n","        tflow.keras.layers.Dense(units=aOutput_shape, activation=\"softmax\")]) # output layer\n","    ### setting metrics and optimization\n","    neural_net.compile(\n","        loss=tflow.keras.losses.CategoricalCrossentropy(), # error function\n","        optimizer=tflow.keras.optimizers.Adam(), # optimizer algorithm\n","        metrics=[\"accuracy\"])\n","    ### building and returning network\n","    neural_net.build(input_shape=aInput_shape)\n","    return neural_net"]},{"cell_type":"markdown","metadata":{"id":"NUXNWXmZxi9O"},"source":["#### Creating Callbacks"]},{"cell_type":"markdown","metadata":{"id":"O6twb53lxnD3"},"source":["**Callbacks are event handler functions that are called at certain model training events.**  \n","The TensorBoard() callback saves a training log that helps in monitoring the training process.  \n","The EarlyStopping() callback halts training when a chosen metric stops improving.  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4pizT23D191Q"},"outputs":[],"source":["### creating tensorboard callback\n","def callbackTensorboard():\n","    \"\"\"\n","    Creates folder structure for TensorBoard logs.\\\n","    Returns TensorBoard callback object.\n","    \"\"\"\n","    log_root = Path(\"./logs\")\n","    log_folder = log_root.joinpath(datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n","    return tflow.keras.callbacks.TensorBoard(log_dir=log_folder)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t8zNAKSw8Gqo"},"outputs":[],"source":["### creating early stopping callback\n","def callbackEarlyStopping():\n","    \"\"\"\n","    Creates and returns an EarlyStopping callback object.\n","    \"\"\"\n","    return tflow.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=5)"]},{"cell_type":"markdown","metadata":{"id":"UUJcuUE-8Lyk"},"source":["#### Training and Saving Neural Network"]},{"cell_type":"markdown","metadata":{},"source":["GPUs have limited amount of memory.  \n","The entire training dataset may not fit into GPU memory.  \n","To resolve this, we split our datasets into batches of ~32 tensors.  \n","The neural network sees only one batch at a time."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["### creating, training, and saving full model\n","recognition_model = createNetwork(aInput_shape=INPUT_SHAPE, aModel_url=MODEL_URL, aOutput_shape=OUTPUT_SHAPE)\n","recognition_model.fit(\n","    x=fTrain_dataset.batch(batch_size=32),\n","    epochs=NUM_EPOCHS,\n","    validation_data=fValid_dataset.batch(batch_size=32),\n","    validation_freq=1,\n","    callbacks=[callbackTensorboard(),callbackEarlyStopping()])\n","recognition_model.save(filepath=\"./models/fullModel\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ifMZVjz18SHw"},"outputs":[],"source":["### creating, training, and saving reduced model\n","recognition_model = createNetwork(aInput_shape=INPUT_SHAPE, aModel_url=MODEL_URL, aOutput_shape=OUTPUT_SHAPE)\n","recognition_model.fit(\n","    x=rTrain_dataset.batch(batch_size=32),\n","    epochs=NUM_EPOCHS,\n","    validation_data=rValid_dataset.batch(batch_size=32),\n","    validation_freq=1,\n","    callbacks=[callbackTensorboard(),callbackEarlyStopping()])\n","recognition_model.save(filepath=\"./models/reducedModel\")"]},{"cell_type":"markdown","metadata":{},"source":["#### Model Evaluation with TensorBoard"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["### loading tensorboard\n","%tensorboard --logdir drive/MyDrive/ColabData/DogRecognition/training_logs"]},{"cell_type":"markdown","metadata":{},"source":["#### Loading Trained Model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["### loading trained model\n","recognition_loaded: tflow.keras.Model = tflow.keras.models.load_model(\n","    filepath=\"./models/reducedModel\",\n","    custom_objects={\"KerasLayer\":thub.KerasLayer})"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["### evaluating loaded model\n","recognition_loaded.evaluate(rValid_dataset.batch(batch_size=32))"]},{"cell_type":"markdown","metadata":{"id":"T9Q38yKAmkB5"},"source":["## Visualizing Predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XSjpPZho_m13"},"outputs":[],"source":["### function plotting image, true label, and top predictions\n","def plotPredictions(aImage=numpy.ndarray([]), aLabel=numpy.ndarray([]), aPred=numpy.ndarray([])):\n","    \"\"\"\n","    Plots an image of a dog, its true breed, and the top predicted breeds.\n","    \"\"\"\n","    ### figure init\n","    pyplot.figure(figsize=(7,4.5))\n","    ### plotting image and true label\n","    image_plot = pyplot.subplot(1, 2, 1)\n","    image_plot.imshow(X=aImage)\n","    image_plot.set_title(label=unique_breeds[numpy.argmax(a=aLabel)], fontsize=10)\n","    image_plot.set_yticks(ticks=[])\n","    image_plot.set_xticks(ticks=[])\n","    ### plotting top 5 predictions\n","    top_indexes = numpy.argsort(a=aPred)[-5:][::-1]\n","    pred_plot = pyplot.subplot(1, 2, 2)\n","    pred_plot.bar(height=aPred[top_indexes], x=range(5))\n","    pred_plot.set_title(label=\"Top Five Predictions\", fontsize=10)\n","    pred_plot.set_ylabel(ylabel=\"Confidence Levels\", fontsize=10)\n","    pred_plot.set_xticks(ticks=range(5), labels=unique_breeds[top_indexes], rotation=\"vertical\")\n","    ### layout and returning\n","    pyplot.tight_layout(h_pad=0.1)\n","    return"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["### making predictions\n","valid_preds: numpy.ndarray = recognition_loaded.predict(x=rValid_dataset.batch(batch_size=32), verbose=True)\n","valid_preds.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5n-wROTTJdQL"},"outputs":[],"source":["### visualizing select predictions\n","INDEX = 14\n","for index,item in enumerate(iterable=rValid_dataset.as_numpy_iterator()):\n","    if index == INDEX:\n","        plotPredictions(aImage=item[0], aLabel=item[1], aPred=valid_preds[INDEX])"]},{"cell_type":"markdown","metadata":{"id":"EYh_3fcIoEx6"},"source":["Challenge: Create a confusion matrix of true labels versus predictions."]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPTgQQN0TBCA4ihfBJyMXrt","gpuType":"T4","mount_file_id":"1JM4XGtvqAm8PHoWANtGNGeeXWwJ8O4hI","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":0}
